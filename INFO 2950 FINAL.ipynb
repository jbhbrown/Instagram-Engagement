{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://sites.google.com/a/chromium.org/chromedriver/getting-started\n",
    "# https://selenium-python.readthedocs.io/installation.html\n",
    "# https://sites.google.com/a/chromium.org/chromedriver/downloads\n",
    "## using Chrome v73, so download chromedriver 73!\n",
    "\n",
    "# !pip install selenium (terminal)\n",
    "## ^^ Don\"t move or rename the folder!\n",
    "\n",
    "# in (chromedriver) terminal:\n",
    "# $ ./chromedriver\n",
    "# Started ChromeDriver\n",
    "# port=9515\n",
    "# version=14.0.836.0\n",
    "\n",
    "\n",
    "# https://towardsdatascience.com/web-scraping-using-selenium-python-8a60f4cf40ab\n",
    "\n",
    "# imports\n",
    "# import selenium\n",
    "from selenium import webdriver\n",
    "import pandas\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "try:    ## NOT using urllib2\n",
    "    from urllib2 import urlopen\n",
    "except ImportError:\n",
    "    from urllib.request import urlopen\n",
    "import csv\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: Do NOT run this code without installing Selenium and Chromedriver (we are using version 73) or you will get errors.Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final project, we will be using multiple APIs in order to accurately create and identify the dataset. We are using selenium, chromedriver, and BeautifulSoup for our project. Our project is based around instagram users and the information that each of the different accounts and their images hold. So far, we have been able to find a dataset of 50 of the most popular Instagram users (accounts). This dataset is from HypeAuditor, a website to help companies connect to Instagram influencers. This dataset was created to inform companies of some of the best Instagram users to work with to reach a wide audience. We have written code to collect the number of followers each of the 50 accounts has. We have also looked at posts from different users and identified the hashtags used, the humber of posts each hashtag has (on all of Instagram posted by all non-private accounts), tagged users, the follower counts of the tagged users, and the exact url of the post. Despite the amount of work we have been able to accomplish, there are still a couple of obstacles we are working to overcome. We also can not yet correctly obtain the hashtags on each post but we can find the correct number of posts per hashtag (on all of Instagram). We wanted to use the data from instagram to find out the relationships of different variables and the number of followers to see if there is a correlation between these data types. We have been able to load this data into multiple .CSV files that we will read to search for patterns and correlations between different variables and account activity (i.e. likes on posts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### if you get 'max tries exceeded with URL' error, RE-RUN THIS CELL\n",
    "driver = webdriver.Chrome('/Users/jbh/Downloads/chromedriver 2')\n",
    "# path to chromedriver: control > click > option > copy path\n",
    "# only run this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://hypeauditor.com/en/top-instagram/'\n",
    "driver.get(website)\n",
    "site_source = driver.page_source    # html source code\n",
    "html = site_source\n",
    "soup = BeautifulSoup(html, 'html.parser')    # the html code for the user's account page\n",
    "soup.prettify()\n",
    "\n",
    "usernames = soup.find_all(\"a\", class_=\"kyb-ellipsis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@cristiano', '@selenagomez', '@kyliejenner', '@leomessi', '@beyonce', '@kendalljenner', '@therock', '@kimkardashian', '@instagram', '@arianagrande', '@neymarjr', '@ddlovato', '@taylorswift', '@justinbieber', '@khloekardashian', '@badgalriri', '@zendaya', '@kourtneykardash', '@nickiminaj', '@shawnmendes', '@emmawatson', '@billieeilish', '@jlo', '@lelepons', '@zayn', '@fcbarcelona', '@robertdowneyjr', '@priyankachopra', '@iamcardib', '@tomholland2013', '@champagnepapi', '@virat.kohli', '@lalalalisa_m', '@aliaabhatt', '@jamesrodriguez10', '@ladygaga', '@emilia_clarke', '@blakelively', '@gigihadid', '@lilireinhart', '@chrishemsworth', '@zacefron', '@kingjames', '@camila_cabello', '@mosalah', '@jennierubyjane', '@realmadrid', '@vancityreynolds', '@mileycyrus', '@jamescharles']\n"
     ]
    }
   ],
   "source": [
    "users = []\n",
    "for x in range(len(usernames)):\n",
    "    user = re.search('>(.*)</a>', str(usernames[x]))\n",
    "    user = user.group(1)\n",
    "    users.append(user)\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_50_ig_users.csv', \"w\") as f:    # w = writable\n",
    "    writer = csv.writer(f)\n",
    "    for user in users:\n",
    "        writer.writerow([user])    # Need the [] or it will write each char individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cristiano', 'selenagomez', 'kyliejenner', 'leomessi', 'beyonce', 'kendalljenner', 'therock', 'kimkardashian', 'instagram', 'arianagrande', 'neymarjr', 'ddlovato', 'taylorswift', 'justinbieber', 'khloekardashian', 'badgalriri', 'zendaya', 'kourtneykardash', 'nickiminaj', 'shawnmendes', 'emmawatson', 'billieeilish', 'jlo', 'lelepons', 'zayn', 'fcbarcelona', 'robertdowneyjr', 'priyankachopra', 'iamcardib', 'tomholland2013', 'champagnepapi', 'virat.kohli', 'lalalalisa_m', 'aliaabhatt', 'jamesrodriguez10', 'ladygaga', 'emilia_clarke', 'blakelively', 'gigihadid', 'lilireinhart', 'chrishemsworth', 'zacefron', 'kingjames', 'camila_cabello', 'mosalah', 'jennierubyjane', 'realmadrid', 'vancityreynolds', 'mileycyrus', 'jamescharles']\n"
     ]
    }
   ],
   "source": [
    "#https://medium.freecodecamp.org/how-to-scrape-websites-with-python-and-beautifulsoup-5946935d93fe\n",
    "# usernames = ['cornelluniversity', 'instagram', 'eggcanvas']    # this will be data gotten from a csv file\n",
    "\n",
    "usernames = []\n",
    "with open('top_50_ig_users.csv', \"r\") as f:\n",
    "    for row in f:\n",
    "        usernames.append(row)\n",
    "        \n",
    "for user in range(len(usernames)):\n",
    "    usernames[user] = usernames[user][1:len(usernames[user])-1]  # get rid of '@' and '/n'\n",
    "    \n",
    "print(usernames)\n",
    "\n",
    "# usernames = ['cornelluniversity', 'instagram']    # this will be data gotten from a csv file\n",
    "website = 'https://www.instagram.com/'\n",
    "\n",
    "POST_DATA = []\n",
    "# img_url = []\n",
    "## Maybe not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.instagram.com/cristiano\n",
      "https://www.instagram.com/selenagomez\n",
      "https://www.instagram.com/kyliejenner\n",
      "https://www.instagram.com/leomessi\n",
      "https://www.instagram.com/beyonce\n",
      "https://www.instagram.com/kendalljenner\n",
      "https://www.instagram.com/therock\n",
      "https://www.instagram.com/kimkardashian\n",
      "https://www.instagram.com/instagram\n",
      "https://www.instagram.com/arianagrande\n",
      "https://www.instagram.com/neymarjr\n",
      "https://www.instagram.com/ddlovato\n",
      "https://www.instagram.com/taylorswift\n",
      "https://www.instagram.com/justinbieber\n",
      "https://www.instagram.com/khloekardashian\n",
      "https://www.instagram.com/badgalriri\n",
      "https://www.instagram.com/zendaya\n",
      "https://www.instagram.com/kourtneykardash\n",
      "https://www.instagram.com/nickiminaj\n",
      "https://www.instagram.com/shawnmendes\n",
      "https://www.instagram.com/emmawatson\n",
      "https://www.instagram.com/billieeilish\n",
      "https://www.instagram.com/jlo\n",
      "https://www.instagram.com/lelepons\n",
      "https://www.instagram.com/zayn\n",
      "https://www.instagram.com/fcbarcelona\n",
      "https://www.instagram.com/robertdowneyjr\n",
      "https://www.instagram.com/priyankachopra\n",
      "https://www.instagram.com/iamcardib\n",
      "https://www.instagram.com/tomholland2013\n",
      "https://www.instagram.com/champagnepapi\n",
      "https://www.instagram.com/virat.kohli\n",
      "https://www.instagram.com/lalalalisa_m\n",
      "https://www.instagram.com/aliaabhatt\n",
      "https://www.instagram.com/jamesrodriguez10\n",
      "https://www.instagram.com/ladygaga\n",
      "https://www.instagram.com/emilia_clarke\n",
      "https://www.instagram.com/blakelively\n",
      "https://www.instagram.com/gigihadid\n",
      "https://www.instagram.com/lilireinhart\n",
      "https://www.instagram.com/chrishemsworth\n",
      "https://www.instagram.com/zacefron\n",
      "https://www.instagram.com/kingjames\n",
      "https://www.instagram.com/camila_cabello\n",
      "https://www.instagram.com/mosalah\n",
      "https://www.instagram.com/jennierubyjane\n",
      "https://www.instagram.com/realmadrid\n",
      "https://www.instagram.com/vancityreynolds\n",
      "https://www.instagram.com/mileycyrus\n",
      "https://www.instagram.com/jamescharles\n",
      "['166m', '150m', '135m', '118m', '127m', '110m', '142m', '138m', '299m', '154m', '116m', '71.6m', '117m', '112m', '93.1m', '70.6m', '56.1m', '78.1m', '102m', '44.2m', '50.6m', '22.2m', '93.4m', '34.4m', '30.5m', '70.1m', '38m', '40m', '44.5m', '19.1m', '57.1m', '33.3m', '19.3m', '33m', '41.3m', '35.6m', '22.4m', '24.6m', '47.6m', '17.3m', '32.7m', '39.3m', '49m', '32.8m', '27m', '16.7m', '71.7m', '30.2m', '93m', '15.2m']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "#### USER PAGE HTML ####\n",
    "posted_by = []    #NEW\n",
    "POST_URLS = []\n",
    "FOLLOWERS = []\n",
    "for user in usernames:    # for each user - get their page\n",
    "    user_site = website + user\n",
    "    print(user_site)\n",
    "    driver.get(user_site)\n",
    "    site_source = driver.page_source    # html source code\n",
    "    \n",
    "    # THIS:\n",
    "    html = site_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')    # the html code for the user's account page\n",
    "    soup.prettify()\n",
    "\n",
    "#### LIKES ON POSTS ####\n",
    "    # use ' <div \"class=v1Nh3\"> '\n",
    "    limit = 0\n",
    "    for post in soup.find_all(\"div\", class_=\"v1Nh3\"):\n",
    "        limit +=1\n",
    "        if limit <= 500:    # only get 500 posts\n",
    "        # ONLY 12 RECENT POSTS will be rendered in html because IG dynamically loads when you scroll\n",
    "            try:\n",
    "                img_url = [a['href'] for a in soup.find_all('a', href=True)]    ## should this be like this?\n",
    "#                 posted_by.append(user)\n",
    "                temp_users = [user for a in soup.find_all('a', href=True)]\n",
    "            except:\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    for x in temp_users:\n",
    "        posted_by.append(x)\n",
    "    POST_URLS.append(img_url)\n",
    "    \n",
    "    clean_arr = []\n",
    "    for followers in soup.find_all(\"span\", class_=\"g47SY\"):\n",
    "        count = followers.parent.find_all('span')[0]    # [ #POSTS, #FOLLOWERS, #FOLLOWING ]\n",
    "        for x in count:\n",
    "            clean_arr.append(x)\n",
    "    try:\n",
    "        follower_count = clean_arr[1]\n",
    "    except:\n",
    "        follower_count = 0    # possibly private account, changed username, etc.\n",
    "    FOLLOWERS.append(str(follower_count))\n",
    "print(FOLLOWERS)\n",
    "print(len(FOLLOWERS))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[166000000, 150000000, 135000000, 118000000, 127000000, 110000000, 142000000, 138000000, 299000000, 154000000, 116000000, 71600000, 117000000, 112000000, 93100000, 70600000, 56100000, 78100000, 102000000, 44200000, 50600000, 22200000, 93400000, 34400000, 30500000, 70100000, 38000000, 40000000, 44500000, 19100000, 57100000, 33300000, 19300000, 33000000, 41300000, 35600000, 22400000, 24600000, 47600000, 17300000, 32700000, 39300000, 49000000, 32800000, 27000000, 16700000, 71700000, 30200000, 93000000, 15200000]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(FOLLOWERS)):    ## get rid of the '.'\n",
    "    FOLLOWERS[i] = str(FOLLOWERS[i])\n",
    "    if not FOLLOWERS[i] == 0:\n",
    "        if '.' in FOLLOWERS[i]:\n",
    "            FOLLOWERS[i] = re.sub('\\.', '', FOLLOWERS[i])\n",
    "            if FOLLOWERS[i][-1] == 'k':\n",
    "                temp = FOLLOWERS[i]\n",
    "                thousands = temp[:len(temp)-1] + '00'\n",
    "                FOLLOWERS[i] = thousands\n",
    "            if FOLLOWERS[i][-1] == 'm':\n",
    "                temp = FOLLOWERS[i]\n",
    "                thousands = temp[:len(temp)-1] + '00000'\n",
    "                FOLLOWERS[i] = thousands\n",
    "        if FOLLOWERS[i][-1] == 'k':\n",
    "            temp = FOLLOWERS[i]\n",
    "            thousands = temp[:len(temp)-1] + '000'\n",
    "            FOLLOWERS[i] = int(thousands)\n",
    "        elif FOLLOWERS[i][-1] == 'm':\n",
    "            temp = FOLLOWERS[i]\n",
    "            thousands = temp[:len(temp)-1] + '000000'\n",
    "            FOLLOWERS[i] = int(thousands)\n",
    "        else:\n",
    "            FOLLOWERS[i] = int(str(FOLLOWERS[i]))\n",
    "            \n",
    "for i in range(len(FOLLOWERS)):    ## get rid of the '.'\n",
    "    FOLLOWERS[i] = int(FOLLOWERS[i])\n",
    "        \n",
    "print(FOLLOWERS)\n",
    "print(len(FOLLOWERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DO NOT NEED TO RUN THIS ####\n",
    "# print(POST_URLS)\n",
    "# print(posted_by)\n",
    "\n",
    "# print(post_count)\n",
    "# print(len(posted_by))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "#### USER'S POSTS ####\n",
    "user_index = -1\n",
    "POSTED_BY = []\n",
    "img_urls = []   # this is the array of actual image URLS -- use this later on\n",
    "for url in POST_URLS:    # get rid of the urls that are not post image urls\n",
    "    user_index +=1\n",
    "    for each in url:\n",
    "        if '/p/' in each:    # '/p/' refers to a post\n",
    "            img_urls.append(each[1:])    # get rid of the first '/' in '/p/'\n",
    "            POSTED_BY.append(usernames[user_index])\n",
    "\n",
    "print(len(img_urls))\n",
    "print(len(POSTED_BY))\n",
    "\n",
    "individual_post_URLS = []\n",
    "for url in img_urls:\n",
    "    individual_post_URLS.append(website + url)\n",
    "    \n",
    "# individual_post_URLS = list(dict.fromkeys(individual_post_URLS))   # get rid of dulpicates\n",
    "#### OR:\n",
    "individual_post_urls = []\n",
    "for i in range(len(individual_post_URLS)):\n",
    "    if not individual_post_URLS[i] in individual_post_urls:\n",
    "        individual_post_urls.append(individual_post_URLS[i])\n",
    "    else:\n",
    "        del POSTED_BY[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "print(len(individual_post_urls))\n",
    "print(len(POSTED_BY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#### CLEANING ####\n",
    "#### FOR SOME POSTS, THE CODE CANNOT GET THE NUMBER OF LIKES, WE WILL NOT INCLUDE THESE POSTS\n",
    "INDIVIDUAL_POST_URLS = []\n",
    "likes_array = []\n",
    "tagged_users_array = []\n",
    "user_index = -1\n",
    "FINAL_POSTED_BY = []\n",
    "\n",
    "for post_url in individual_post_urls:    #### DO NOT ITERATE THROUGH THE ENTIRE LIST WHEN TESTING\n",
    "    driver.get(post_url)\n",
    "    site_source = driver.page_source    # html source code\n",
    "    soup = BeautifulSoup(site_source, 'html.parser')\n",
    "    soup.prettify()\n",
    "    user_index +=1\n",
    "    try:\n",
    "        for likes in soup.find_all(\"a\", class_=\"zV_Nj\"):\n",
    "            num_likes = str(likes.parent.find_all('span')[0])\n",
    "            INDIVIDUAL_POST_URLS.append(post_url)\n",
    "            FINAL_POSTED_BY.append(POSTED_BY[user_index])\n",
    "    except:\n",
    "        continue\n",
    "   \n",
    "    #### LIKES ON POSTS ####\n",
    "    for likes in soup.find_all(\"a\", class_=\"zV_Nj\"):\n",
    "        try:\n",
    "            num_likes = str(likes.parent.find_all('span')[0])\n",
    "            if not num_likes == '':\n",
    "                likes_array.append(num_likes)\n",
    "            else:\n",
    "                likes_array.append(str(0))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n",
      "461\n"
     ]
    }
   ],
   "source": [
    "print(len(INDIVIDUAL_POST_URLS))\n",
    "print(len(FINAL_POSTED_BY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(likes_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n",
      "461\n",
      "461\n"
     ]
    }
   ],
   "source": [
    "print(len(INDIVIDUAL_POST_URLS))\n",
    "print(len(likes_array))\n",
    "print(len(INDIVIDUAL_POST_URLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5098731, 5301028, 7157581, 4580564, 3771284, 4224793, 7048967, 3248157, 8782995, 4717402, 5641286, 11489036, 3568235, 5405003, 6830455, 11874479, 4380808, 5943637, 713342, 5409551, 2102408, 3255212, 5736617, 1291882, 5066032, 3705964, 4615472, 6044283, 8027466, 3433951, 7731739, 3923092, 9520783, 10241857, 4032622, 5706054, 3879502, 3202702, 5225743, 2650538, 2121500, 3575660, 6259548, 7179078, 3413075, 2130747, 2932538, 3709045, 1515576, 3945904, 2699360, 1668529, 4282747, 9472971, 4294072, 3035329, 4592971, 3656197, 2102117, 338580, 1611282, 2295898, 1859537, 1264238, 2553547, 2725333, 4743112, 4077553, 973955, 1300549, 2659641, 2097946, 3623927, 1753983, 262113, 365128, 312478, 2804501, 3487246, 6127537, 746004, 852367, 970361, 1034632, 925612, 1068805, 1733670, 976055, 373931, 4057650, 2281977, 2615778, 1787385, 926702, 937339, 2243900, 1637258, 1345649, 920988, 854691, 1265570, 3615848, 1304394, 5617028, 1482771, 1149259, 2290350, 1233904, 3123168, 3934128, 3209630, 1066373, 2832438, 2687937, 3946903, 4686840, 1348781, 1581430, 1877439, 1770415, 1475976, 1460224, 2489445, 2551226, 1491501, 1601555, 2531098, 1892459, 701433, 801432, 1134062, 1121730, 1222017, 3070267, 1412767, 575836, 1393965, 2379453, 369586, 1828654, 2101229, 501901, 425673, 902047, 2979074, 1511069, 1360611, 1754776, 4384173, 2603443, 3086014, 2627166, 501509, 1492230, 1851844, 2254358, 2221666, 5943835, 4714762, 2470307, 2694738, 6089829, 1351334, 1604382, 816018, 1151628, 1267109, 2560593, 1916722, 2123223, 1098904, 1819718, 3293158, 1114483, 1907478, 3057084, 2412709, 1390228, 1177945, 3242528, 2990638, 3506970, 6714468, 2443805, 3327695, 1576906, 432054, 228033, 2160123, 2876300, 2136999, 4724353, 1041647, 4477822, 3796243, 1790026, 1343347, 897319, 3438745, 3736397, 4184431, 4548687, 3370601, 5103106, 4405830, 4657105, 4712777, 1141499, 2368499, 1259366, 308698, 709446, 1330792, 3493726, 2742276, 2142045, 2841937, 2447080, 2342780, 803696, 2528568, 3039698, 2357512, 3800277, 2686890, 2301271, 1020373, 1135372, 707847, 1076877, 628478, 1471477, 1652356, 1561373, 1968037, 7414934, 826838, 6346293, 11587755, 6681938, 7620003, 605543, 957481, 793728, 1084137, 628573, 976445, 2118384, 1273016, 1436441, 1645035, 1645941, 2355869, 1391825, 290969, 2673655, 1523013, 1514229, 4193836, 1424533, 1085156, 4082867, 5146114, 3468381, 4873097, 3314120, 3626781, 3298284, 2266777, 1172882, 1061049, 968162, 2740505, 1201457, 1418012, 455447, 929727, 570290, 634726, 1668488, 1713366, 2238601, 1767820, 1874805, 1754315, 2315372, 3933271, 1906583, 1790060, 2351316, 2863255, 2467140, 2964525, 2739917, 2872423, 2593013, 3264765, 3187701, 2205604, 2974959, 1487666, 758757, 1818838, 2126264, 1661824, 1147208, 1755980, 575460, 2079201, 872874, 1776449, 607023, 1557476, 670928, 1268285, 1613137, 1909068, 1197811, 1354614, 812600, 1508985, 950460, 1120107, 1560417, 1361753, 2451994, 1459094, 1254355, 1241911, 2233039, 1816111, 2656004, 1556341, 3064113, 4693339, 2197921, 5581208, 1167911, 2902410, 3724909, 2408552, 1612885, 4090729, 2727480, 1500644, 1979166, 2131918, 2901829, 728315, 3417039, 2796815, 2105337, 1220858, 1441225, 578783, 428758, 995682, 1195878, 1151418, 1673283, 1965611, 1025829, 1014947, 1153082, 526944, 2924745, 3249311, 1961175, 4112214, 1670214, 4697057, 3114038, 5743251, 2899062, 5256844, 2316295, 1354899, 3617717, 3783115, 5234306, 5149476, 2436909, 1237027, 1702959, 1323006, 809756, 2973242, 1991624, 1292015, 1667882, 546320, 1053595, 830733, 863367, 1596776, 809267, 1635667, 1956313, 1403048, 817361, 1432589, 858930, 1646956, 1830698, 1018423, 2163739, 1845768, 893957, 1306043, 2888103, 1169463, 3705716, 1866788, 2278644, 2092189, 2709123, 1552529, 904223, 3090510, 1567807, 2807556, 1792029, 2179029, 2753796, 2644964, 2768270, 2998173, 2374650, 704954, 868576, 813633, 1121254, 557343, 887164, 2159479, 1235525, 1274699, 1486573, 1504996, 2567155, 1712035, 1571778, 651128, 703602, 1020349, 1558323, 1970252, 583544, 1360368, 1256635, 3716410, 2023978, 2084986, 2653227, 2215269, 3675032, 2592686, 3022652, 2454967, 3538417, 3160296]\n"
     ]
    }
   ],
   "source": [
    "#### LIKES ON POSTS ####\n",
    "likes_arr = []\n",
    "for likes in likes_array:    # get the # of likes in string format\n",
    "    num_likes = re.search('<span>(.*)</span>', likes)\n",
    "    likes_arr.append(num_likes.group(1))\n",
    "\n",
    "LIKES_ARRAY = []\n",
    "for likes in likes_arr:    # get rid of the comma in # likes and cast to int\n",
    "    num = re.sub(',', '', likes)\n",
    "    LIKES_ARRAY.append(int(num))\n",
    "print(LIKES_ARRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['null', 'null', 'null', 'null', 'cr7_footwear', 'null', 'nikefootball', 'null', 'null', 'null', 'null', 'krahs', 'oprah', 'null', 'null', 'null', 'coach', 'null', 'null', 'null', 'null', 'null', 'sashasamsonova', 'kylieskin', 'null', 'null', 'versace', 'null', 'null', 'null', 'null', 'xavi', 'null', 'null', 'miguelruizfcb', 'pastisseriabaires', 'null', 'otro', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'mrmikerosenthal', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'kevinhart4real', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'manfredthierrymugler', 'null', 'kkwbeauty', 'null', 'null', 'null', 'null', 'null', 'susan_alexandra', 'podsandthecity', 'null', 'the_hula', 'ruby_marylennox', 'null', 'theconeycats', 'null', 'null', 'alfredoflores', 'null', 'tileystrozewski', 'null', 'givenchyofficial', 'null', 'null', 'dieselfragrances', 'null', 'null', 'nadine.goncalves', 'null', 'marquinhosm5', 'null', 'null', 'null', 'null', 'null', 'scooterbraun', 'null', 'null', '1chrislight', 'null', 'null', 'null', 'winterstone', 'null', 'null', 'null', 'paulaabdul', 'brendonurie', 'null', 'null', 'null', 'null', 'null', 'teddysphotos', 'null', 'null', 'null', 'null', 'miyakemakeup', 'null', 'null', 'null', 'dipd_n_dripd', 'null', 'null', 'null', 'andrewfitzsimons', 'kimkardashian', 'kkwfragrance', 'null', 'null', 'null', 'null', 'bootsuk', 'null', 'dennisleupold', 'null', 'null', 'null', 'hbo', 'null', 'tylersphotos', 'null', 'euphoria', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'poosh', 'realisadiamond', 'null', 'null', 'null', 'null', 'null', 'null', 'letthelordbewithyou', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'josiahvandien', 'null', 'null', 'zilver', 'null', 'null', 'null', 'teatumjones', 'null', 'britishfilminstitute', 'evawuk', 'null', 'goodonyou_app', 'null', 'drdenismukwege', 'billboard', 'blohsh', 'null', 'finneas', 'imran_potato', 'joyrichla', 'vandythepink', 'gigihadid', 'tsuwoop_', 'null', 'null', 'todayshow', 'iamscottevans', 'null', 'null', 'null', 'tobypons', 'null', 'null', 'hannahstocking', 'null', 'null', 'null', 'null', 'thekooples', 'null', 'null', 'null', 'null', 'fcbarcelona', 'null', 'kingarturo23oficial', 'sergiroberto', 'null', 'null', 'null', 'null', 'null', 'jalithgow', 'null', 'null', 'null', 'jimmy_rich', 'null', 'null', 'kevinjonas', 'null', 'null', 'joejonas', 'mimi', 'null', 'null', 'null', 'null', 'nickjonas', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'nellichristine', 'null', 'harryholland64', 'null', 'null', 'null', 'null', 'dougliman', 'raptors', 'null', 'null', 'null', 'antsoulo', 'null', 'null', 'tiffanycalver', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'dalesteyn', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'dualipa', 'null', 'sonirazdan', 'null', 'null', 'null', 'null', 'ananyapanday', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'brandonmaxwell', 'tiffanyandco', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'gameofthrones', 'null', 'null', 'null', 'null', 'null', 'null', 'voguespain', 'null', 'null', 'djquintero', 'louboutinworld', 'amytags', 'null', 'null', 'null', 'vancityreynolds', 'sophiatravaglia', 'thomastheboxer', 'null', 'ralphlauren', 'bellahadid', 'null', 'null', 'michaelkors', 'null', 'null', 'null', 'lilmami_lani', 'null', 'null', 'null', 'davestanwell', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'maisonvalentino', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'brianhammers', 'tribeca', 'theellenshow', 'jimmykimmel', 'lilyjcollins', 'null', 'netflix', 'null', 'mavcarter', 'null', 'null', 'carmeloanthony', 'null', 'pr_rwtw', 'null', 'null', 'null', 'chrisblockd', 'null', 'null', 'null', 'ash_kholm', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'null', 'gentlemonster', 'chanelofficial', 'null', 'null', 'null', 'blackpinkofficial', 'adidasoriginals', 'null', 'null', 'null', 'null', 'brahim', 'null', 'viniciusjunior', 'marcelotwelve', 'jesusvallejo1997', 'marianodiazmejia', 'null', 'null', 'null', 'null', 'serafinosays', 'ilariaurbinati', 'null', 'null', 'null', 'diggzy', 'null', 'null', 'null', 'null', 'null', 'null', 'youtube', 'bodyelectrictattoo', 'nbc', 'null', 'louisvuitton', 'null', 'nikita_dragun', 'balenciaga', 'lauramellado', 'null', 'morphebrushes']\n",
      "461\n",
      "461\n"
     ]
    }
   ],
   "source": [
    "#### TAGGED USERS ---- ONLY IF TAGGED IN PHOTO (I.E. NOT TAGGED IN DESCRIPTION) ####\n",
    "tagged_users_array = []\n",
    "for post_url in INDIVIDUAL_POST_URLS:\n",
    "#     print('\\n')\n",
    "    driver.get(post_url)\n",
    "    site_source = driver.page_source    # html source code\n",
    "    soup = BeautifulSoup(site_source, 'html.parser')\n",
    "    soup.prettify()\n",
    "##### COMMENT WHAT IS HAPPENING HERE:\n",
    "    try:\n",
    "        x = soup.find_all(\"span\", class_=\"eg3Fv\")\n",
    "        if str(x) == '[]':\n",
    "            raise Exception('Exeption!')\n",
    "        try:\n",
    "            driver.get(post_url)\n",
    "            site_source = driver.page_source    # html source code\n",
    "            soup = BeautifulSoup(site_source, 'html.parser')\n",
    "            soup.prettify()\n",
    "            x = str(soup.find_all(\"span\", class_=\"eg3Fv\"))\n",
    "            user_tags = re.search('(?:>)(([A-Za-z0-9_](?:(?:[A-Za-z0-9_]|(?:\\.(?!\\.))){0,28}(?:[A-Za-z0-9_]))?))(?:<)', x)\n",
    "            if not str(user_tags) == '[]' and user_tags.group(1) not in tagged_users_array:\n",
    "                tagged_users_array.append(user_tags.group(1))\n",
    "            else:\n",
    "                tagged_users_array.append('null')\n",
    "        except:\n",
    "            tagged_users_array.append('null')    # unlikely to be cought here\n",
    "    except:\n",
    "        tagged_users_array.append('null')\n",
    "        \n",
    "print(tagged_users_array)\n",
    "print(len(tagged_users_array))\n",
    "print(len(INDIVIDUAL_POST_URLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n"
     ]
    }
   ],
   "source": [
    "tagged_user_urls = []\n",
    "for tagged in tagged_users_array:\n",
    "    if not tagged == 'null':\n",
    "        url = str('https://www.instagram.com/' + tagged)\n",
    "        tagged_user_urls.append(url)\n",
    "    else:\n",
    "        tagged_user_urls.append('null')\n",
    "# print(tagged_user_urls)\n",
    "print(len(tagged_user_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, '1.1m', 0, '37.7m', 0, 0, 0, 0, '365k', '16.2m', 0, 0, 0, '3.8m', 0, 0, 0, 0, 0, '586k', '1m', 0, 0, '17.8m', 0, 0, 0, 0, '3.1m', 0, 0, '1.5m', '5,453', 0, '744k', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '171k', 0, 0, 0, 0, 0, 0, 0, 0, '74.3m', 0, 0, 0, 0, 0, 0, 0, 0, 0, '359k', 0, '3.1m', 0, 0, 0, 0, 0, '85.9k', '14.1k', 0, '261k', '124k', 0, '15.3k', 0, 0, '2.5m', 0, '20.6k', 0, '12.8m', 0, 0, '25.3k', 0, 0, '950k', 0, '2.8m', 0, 0, 0, 0, 0, '3.1m', 0, 0, '5,755', 0, 0, 0, '385k', 0, 0, 0, '277k', '4.4m', 0, 0, 0, 0, 0, '28.8m', 0, 0, 0, 0, '27.1k', 0, 0, 0, '32k', 0, 0, 0, '348k', '138m', '731k', 0, 0, 0, 0, '837k', 0, '103k', 0, 0, 0, '2.7m', 0, '224k', 0, '63.1k', 0, 0, 0, 0, 0, 0, 0, '2.8m', '32.4k', 0, 0, 0, 0, 0, 0, '21.5m', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '359k', 0, 0, '98k', 0, 0, 0, '12k', 0, '233k', '812', 0, '97.3k', 0, '28.6k', '6.9m', '543k', 0, '650k', '152k', '196k', '176k', '47.6m', '86.1k', 0, 0, '2.1m', '136k', 0, 0, 0, '223k', 0, 0, '16.4m', 0, 0, 0, 0, '934k', 0, 0, 0, 0, '70.1m', 0, '9.8m', '6.5m', 0, 0, 0, 0, 0, '18.1k', 0, 0, 0, '177k', 0, 0, '4m', 0, 0, '10.3m', '228k', 0, 0, 0, 0, '23.8m', 0, 0, 0, 0, 0, 0, 0, 0, '76.2k', 0, '589k', 0, 0, 0, 0, '17.6k', '1.9m', 0, 0, 0, '51.1k', 0, 0, '44.6k', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '1.2m', 0, 0, 0, 0, 0, 0, 0, 0, 0, '29.5m', 0, '196k', 0, 0, 0, 0, '2.5m', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '493k', '10.4m', 0, 0, 0, 0, 0, 0, 0, 0, '10m', 0, 0, 0, 0, 0, 0, '1.3m', 0, 0, '16.6k', '12.4m', '2,102', 0, 0, 0, '30.2m', '1,134', '124k', 0, '10.4m', '24.3m', 0, 0, '14.5m', 0, 0, 0, '128k', 0, 0, 0, '34.4k', 0, 0, 0, 0, 0, 0, 0, '12.3m', 0, 0, 0, 0, 0, 0, 0, 0, '1,771', '274k', '71.7m', '2m', '15.1m', 0, '14.6m', 0, '209k', 0, 0, '6.4m', 0, '34.7k', 0, 0, 0, '10k', 0, 0, 0, '520k', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '366k', '34.6m', 0, 0, 0, '18.4m', '33.5m', 0, 0, 0, 0, '940k', 0, '6.4m', '37.7m', '633k', '1.8m', 0, 0, 0, 0, '83.8k', '170k', 0, 0, 0, '97.3k', 0, 0, 0, 0, 0, 0, '19.5m', '96.9k', '537k', 0, '31.7m', 0, '4.6m', '9.5m', '453k', 0, '9.6m']\n",
      "461\n"
     ]
    }
   ],
   "source": [
    "#### TAGGED USER PAGE HTML ####\n",
    "tagged_user_followers = []\n",
    "for user in tagged_user_urls:    # for each user - get their page\n",
    "    if not user == 'null':\n",
    "        driver.get(user)\n",
    "        site_source = driver.page_source    # html source code\n",
    "        html = site_source\n",
    "        # soup = BeautifulSoup(urlopen(user_site), 'html.parser')    # the html code for the user's account page\n",
    "        soup = BeautifulSoup(html, 'html.parser')    # the html code for the user's account page\n",
    "        soup.prettify()\n",
    "        clean_arr = []\n",
    "        for followers in soup.find_all(\"span\", class_=\"g47SY\"):\n",
    "            count = followers.parent.find_all('span')[0]    # [ #POSTS, #FOLLOWERS, #FOLLOWING ]\n",
    "            for x in count:\n",
    "                clean_arr.append(x)\n",
    "        try:\n",
    "            follower_count = clean_arr[1]\n",
    "        except:\n",
    "            follower_count = 0    # possibly private account, changed username, etc.\n",
    "        tagged_user_followers.append(str(follower_count))\n",
    "    else:\n",
    "        tagged_user_followers.append(0)\n",
    "print(tagged_user_followers)\n",
    "print(len(tagged_user_followers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1100000, 0, 37700000, 0, 0, 0, 0, 365000, 16200000, 0, 0, 0, 3800000, 0, 0, 0, 0, 0, 586000, 1000000, 0, 0, 17800000, 0, 0, 0, 0, 3100000, 0, 0, 1500000, 5453, 0, 744000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 171000, 0, 0, 0, 0, 0, 0, 0, 0, 74300000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 359000, 0, 3100000, 0, 0, 0, 0, 0, 85900, 14100, 0, 261000, 124000, 0, 15300, 0, 0, 2500000, 0, 20600, 0, 12800000, 0, 0, 25300, 0, 0, 950000, 0, 2800000, 0, 0, 0, 0, 0, 3100000, 0, 0, 5755, 0, 0, 0, 385000, 0, 0, 0, 277000, 4400000, 0, 0, 0, 0, 0, 28800000, 0, 0, 0, 0, 27100, 0, 0, 0, 32000, 0, 0, 0, 348000, 138000000, 731000, 0, 0, 0, 0, 837000, 0, 103000, 0, 0, 0, 2700000, 0, 224000, 0, 63100, 0, 0, 0, 0, 0, 0, 0, 2800000, 32400, 0, 0, 0, 0, 0, 0, 21500000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 359000, 0, 0, 98000, 0, 0, 0, 12000, 0, 233000, 812, 0, 97300, 0, 28600, 6900000, 543000, 0, 650000, 152000, 196000, 176000, 47600000, 86100, 0, 0, 2100000, 136000, 0, 0, 0, 223000, 0, 0, 16400000, 0, 0, 0, 0, 934000, 0, 0, 0, 0, 70100000, 0, 9800000, 6500000, 0, 0, 0, 0, 0, 18100, 0, 0, 0, 177000, 0, 0, 4000000, 0, 0, 10300000, 228000, 0, 0, 0, 0, 23800000, 0, 0, 0, 0, 0, 0, 0, 0, 76200, 0, 589000, 0, 0, 0, 0, 17600, 1900000, 0, 0, 0, 51100, 0, 0, 44600, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1200000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29500000, 0, 196000, 0, 0, 0, 0, 2500000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 493000, 10400000, 0, 0, 0, 0, 0, 0, 0, 0, 10000000, 0, 0, 0, 0, 0, 0, 1300000, 0, 0, 16600, 12400000, 2102, 0, 0, 0, 30200000, 1134, 124000, 0, 10400000, 24300000, 0, 0, 14500000, 0, 0, 0, 128000, 0, 0, 0, 34400, 0, 0, 0, 0, 0, 0, 0, 12300000, 0, 0, 0, 0, 0, 0, 0, 0, 1771, 274000, 71700000, 2000000, 15100000, 0, 14600000, 0, 209000, 0, 0, 6400000, 0, 34700, 0, 0, 0, 10000, 0, 0, 0, 520000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 366000, 34600000, 0, 0, 0, 18400000, 33500000, 0, 0, 0, 0, 940000, 0, 6400000, 37700000, 633000, 1800000, 0, 0, 0, 0, 83800, 170000, 0, 0, 0, 97300, 0, 0, 0, 0, 0, 0, 19500000, 96900, 537000, 0, 31700000, 0, 4600000, 9500000, 453000, 0, 9600000]\n",
      "461\n"
     ]
    }
   ],
   "source": [
    "## not the most efficient..           \n",
    "for i in range(len(tagged_user_followers)):    ## get rid of the '.'\n",
    "    tagged_user_followers[i] = str(tagged_user_followers[i])\n",
    "    if not tagged_user_followers[i] == 0:\n",
    "        if '.' in tagged_user_followers[i]:\n",
    "            tagged_user_followers[i] = re.sub('\\.', '', tagged_user_followers[i])\n",
    "            if tagged_user_followers[i][-1] == 'k':\n",
    "                temp = tagged_user_followers[i]\n",
    "                thousands = temp[:len(temp)-1] + '00'\n",
    "                tagged_user_followers[i] = thousands\n",
    "            if tagged_user_followers[i][-1] == 'm':\n",
    "                temp = tagged_user_followers[i]\n",
    "                thousands = temp[:len(temp)-1] + '00000'\n",
    "                tagged_user_followers[i] = thousands\n",
    "        tagged_user_followers[i] = re.sub(',', '', tagged_user_followers[i])\n",
    "        if tagged_user_followers[i][-1] == 'k':\n",
    "            temp = tagged_user_followers[i]\n",
    "            thousands = temp[:len(temp)-1] + '000'\n",
    "            tagged_user_followers[i] = int(thousands)\n",
    "        elif tagged_user_followers[i][-1] == 'm':\n",
    "            temp = tagged_user_followers[i]\n",
    "            thousands = temp[:len(temp)-1] + '000000'\n",
    "            tagged_user_followers[i] = int(thousands)\n",
    "        else:\n",
    "            tagged_user_followers[i] = int(str(tagged_user_followers[i]))            \n",
    "        \n",
    "for i in range(len(tagged_user_followers)):    ## get rid of the '.'\n",
    "    tagged_user_followers[i] = int(tagged_user_followers[i])\n",
    "        \n",
    "print(tagged_user_followers)\n",
    "print(len(tagged_user_followers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n"
     ]
    }
   ],
   "source": [
    "print(len(INDIVIDUAL_POST_URLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "['28.9k Comments', '31k Comments', '42.3k Comments', '28.1k Comments', '29.7k Comments', '18.4k Comments', '46.9k Comments', '13.1k Comments', '55.2k Comments', '26.7k Comments', '58.8k Comments', '152.1k Comments', '22.5k Comments', '25.1k Comments', '69.1k Comments', '183.4k Comments', '44.6k Comments', '73.2k Comments', '10k Comments', '75.5k Comments', '539 Comments', '898 Comments', '19.2k Comments', '33.2k Comments', '72.2k Comments', '97.3k Comments', '55.9k Comments', '53.2k Comments', '60.6k Comments', '18k Comments', '55k Comments', '15.7k Comments', '153.8k Comments', '95k Comments', '15.2k Comments', '28.5k Comments', '23.9k Comments', '11.7k Comments', '31.9k Comments', '22.3k Comments', '15.1k Comments', '35.9k Comments', '80.5k Comments', '88.7k Comments', '50.3k Comments', '19.5k Comments', '23.7k Comments', '30.5k Comments', '948 Comments', '22.3k Comments', '969 Comments', '524 Comments', '17.1k Comments', '122.2k Comments', '22.3k Comments', '20.8k Comments', '21.7k Comments', '414 Comments', '196 Comments', '656 Comments', '350 Comments', '388 Comments', '957 Comments', '850 Comments', '607 Comments', '351 Comments', '12.3k Comments', '21.2k Comments', '458 Comments', '435 Comments', '788 Comments', '10.4k Comments', '14.6k Comments', '439 Comments', '594 Comments', '324 Comments', '637 Comments', '16.9k Comments', '28.9k Comments', '63.9k Comments', '463 Comments', '11.1k Comments', '842 Comments', '196 Comments', '149 Comments', '15.6k Comments', '13.7k Comments', '11.2k Comments', '395 Comments', '17.2k Comments', '991 Comments', '18.1k Comments', '277 Comments', '044 Comments', '444 Comments', '10.5k Comments', '329 Comments', '5 Comments', '7 Comments', '12 Comments', '25 Comments', '66 Comments', '11 Comments', '169 Comments', '32 Comments', '21 Comments', '32.3k Comments', '719 Comments', '38.6k Comments', '61.5k Comments', '51.4k Comments', '986 Comments', '31.4k Comments', '33.4k Comments', '65.9k Comments', '83.2k Comments', '0 Comments', '0 Comments', '0 Comments', '0 Comments', '0 Comments', '0 Comments', '0 Comments', '0 Comments', '13.5k Comments', '17.1k Comments', '21.4k Comments', '21.4k Comments', '015 Comments', '423 Comments', '091 Comments', '483 Comments', '209 Comments', '17.7k Comments', '549 Comments', '858 Comments', '942 Comments', '13.2k Comments', '614 Comments', '924 Comments', '017 Comments', '005 Comments', '067 Comments', '10.1k Comments', '39.7k Comments', '15.1k Comments', '33k Comments', '12.9k Comments', '41.5k Comments', '18.3k Comments', '21.1k Comments', '18.2k Comments', '839 Comments', '419 Comments', '631 Comments', '440 Comments', '933 Comments', '44.1k Comments', '19.4k Comments', '23.2k Comments', '11.9k Comments', '53.3k Comments', '329 Comments', '957 Comments', '363 Comments', '973 Comments', '895 Comments', '12.5k Comments', '304 Comments', '11.7k Comments', '741 Comments', '444 Comments', '23.6k Comments', '522 Comments', '32.6k Comments', '53.8k Comments', '233k Comments', '27k Comments', '32.3k Comments', '10.5k Comments', '645 Comments', '542 Comments', '524 Comments', '460 Comments', '910 Comments', '47.8k Comments', '374 Comments', '13.5k Comments', '936 Comments', '430 Comments', '979 Comments', '494 Comments', '27.8k Comments', '30.1k Comments', '40.5k Comments', '63.3k Comments', '24.9k Comments', '42.3k Comments', '36.2k Comments', '34.4k Comments', '32.9k Comments', '840 Comments', '19.2k Comments', '661 Comments', '277 Comments', '400 Comments', '11.5k Comments', '41.4k Comments', '12.4k Comments', '10.9k Comments', '22k Comments', '11.4k Comments', '48.8k Comments', '10.5k Comments', '46.9k Comments', '46.6k Comments', '27.6k Comments', '84.3k Comments', '41.7k Comments', '31.5k Comments', '21.1k Comments', '563 Comments', '248 Comments', '249 Comments', '826 Comments', '16.5k Comments', '22k Comments', '34.9k Comments', '168.5k Comments', '101.7k Comments', '839 Comments', '47.4k Comments', '87.2k Comments', '120.9k Comments', '128.6k Comments', '944 Comments', '821 Comments', '129 Comments', '089 Comments', '093 Comments', '137 Comments', '24.4k Comments', '970 Comments', '12.7k Comments', '418 Comments', '334 Comments', '039 Comments', '36.2k Comments', '27.2k Comments', '39.1k Comments', '63.4k Comments', '16.3k Comments', '19.1k Comments', '18k Comments', '12.9k Comments', '104 Comments', '59 Comments', '40 Comments', '266 Comments', '79 Comments', '71 Comments', '44 Comments', '92 Comments', '41 Comments', '35 Comments', '43 Comments', '16.2k Comments', '21.2k Comments', '14.7k Comments', '15.6k Comments', '20.6k Comments', '23.4k Comments', '16.7k Comments', '36.3k Comments', '25k Comments', '12.4k Comments', '15k Comments', '424 Comments', '686 Comments', '383 Comments', '13.7k Comments', '10.4k Comments', '790 Comments', '429 Comments', '413 Comments', '567 Comments', '548 Comments', '856 Comments', '971 Comments', '762 Comments', '625 Comments', '575 Comments', '11.1k Comments', '14.3k Comments', '901 Comments', '10.1k Comments', '352 Comments', '606 Comments', '093 Comments', '190 Comments', '723 Comments', '429 Comments', '20.1k Comments', '006 Comments', '032 Comments', '018 Comments', '18.6k Comments', '34.5k Comments', '25k Comments', '50k Comments', '16.7k Comments', '133 Comments', '77.4k Comments', '262 Comments', '11.2k Comments', '12.4k Comments', '496 Comments', '354 Comments', '944 Comments', '592 Comments', '481 Comments', '238 Comments', '692 Comments', '763 Comments', '023 Comments', '148 Comments', '499 Comments', '089 Comments', '587 Comments', '12.7k Comments', '12.1k Comments', '600 Comments', '15.9k Comments', '515 Comments', '33.7k Comments', '22k Comments', '26.6k Comments', '10.8k Comments', '41.2k Comments', '610 Comments', '761 Comments', '079 Comments', '15k Comments', '20.4k Comments', '23k Comments', '588 Comments', '074 Comments', '12.1k Comments', '691 Comments', '169 Comments', '596 Comments', '429 Comments', '155 Comments', '815 Comments', '076 Comments', '196 Comments', '275 Comments', '696 Comments', '356 Comments', '231 Comments', '10.8k Comments', '14.7k Comments', '15.1k Comments', '021 Comments', '682 Comments', '670 Comments', '920 Comments', '20.5k Comments', '784 Comments', '20.8k Comments', '19.1k Comments', '321 Comments', '10.2k Comments', '30.6k Comments', '847 Comments', '44.4k Comments', '14.8k Comments', '17.2k Comments', '15.5k Comments', '23.6k Comments', '818 Comments', '428 Comments', '25.4k Comments', '769 Comments', '18.5k Comments', '10.3k Comments', '11.3k Comments', '17.1k Comments', '21.2k Comments', '12.6k Comments', '28.8k Comments', '22.4k Comments', '832 Comments', '10.9k Comments', '911 Comments', '429 Comments', '104 Comments', '189 Comments', '337 Comments', '079 Comments', '699 Comments', '416 Comments', '246 Comments', '355 Comments', '747 Comments', '949 Comments', '539 Comments', '178 Comments', '425 Comments', '709 Comments', '578 Comments', '623 Comments', '933 Comments', '634 Comments', '229.4k Comments', '18.4k Comments', '17.2k Comments', '20.7k Comments', '17.7k Comments', '22.9k Comments', '13.3k Comments', '30.5k Comments', '327 Comments', '51.5k Comments', '22.3k Comments']\n"
     ]
    }
   ],
   "source": [
    "#### #HASHTAGS ####\n",
    "hrefs = []\n",
    "hashtags = []\n",
    "COMMENTS = []\n",
    "for post_url in INDIVIDUAL_POST_URLS:\n",
    "    driver.get(post_url)\n",
    "    site_source = driver.page_source    # html source code\n",
    "    soup = BeautifulSoup(site_source, 'html.parser')\n",
    "    soup.prettify()  \n",
    "    temp = []\n",
    "    for div in soup.find_all(\"div\", {\"class\": \"C4VMK\"}):\n",
    "        try:\n",
    "            for span in div.find_all(\"span\"):\n",
    "                txt = re.findall(\"#([A-Za-z0-9_](?:(?:[A-Za-z0-9_]|(?:\\.(?!\\.))){0,28}(?:[A-Za-z0-9_]))?)</a>\", str(span)) \n",
    "                temp.append(txt[0])\n",
    "        except:\n",
    "            continue \n",
    "    hashtags.append(temp)\n",
    "\n",
    "    for comments in soup.find_all(\"script\", {'type':'application/ld+json'}):\n",
    "        comment_count = re.findall(\"[0-9]+?[\\.]*[0-9]*[k]* Comments\", str(comments))\n",
    "        if len(comment_count) == 0:\n",
    "            COMMENTS('0 Comments')\n",
    "        for x in comment_count:\n",
    "            COMMENTS.append(x)\n",
    "            \n",
    "print('done')\n",
    "print(COMMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['finoallafine'], [], ['pestanacr7'], ['finoallafine'], [], ['TopTraining'], [], [], [], [], ['followme'], [], [], ['90svintage'], [], [], ['CoachNY'], ['Haverdade'], [], [], ['COMINGSOON'], [], ['HappyMothersDay'], ['KYLIESKIN'], ['KylieSkin', 'healthylifestyle'], [], [], ['healthylifestyle'], [], [], [], [], [], [], [], [], [], ['OurOtherClub'], ['ultraboost'], ['sailormoon', 'sailormoon', 'NaarNewYork'], ['DADABHIGHENDAPPAREL'], [], [], [], ['freebritney', 'beastmode'], ['RIP'], ['STAY_STRONG'], ['blacklove'], [], ['crueltynotfashion'], [], [], ['TiffanyBlueBook'], [], ['MOONbyKendall'], ['moon_partner'], [], [], ['MYCALVINS'], ['JUMANJI', '_classic_mode99', 'followme'], [], [], ['JUMANJI'], ['JUMANJI'], ['JUMANJI', 'goodpeople'], ['JUMANJI'], ['JUMANJI'], ['gratefulSOB'], ['KKWBEAUTY', 'dreamsdocometrue'], ['BestFriendsAss'], [], [], [], [], ['KKWBEAUTY', 'kkwbeauty', 'kkwbeauty'], ['KKWBEAUTY', 'kkwbeauty'], ['KKWBEAUTY'], [], [], [], ['MothersDay'], [], ['WeeklyFluff'], ['Ramadan', '_classic_mode99'], ['APAheritagemonth'], [], ['WHPgoingplaces'], ['WeeklyFluff'], [], [], [], [], ['topsinger'], ['arivenchy'], [], ['arivenchy', 'longhair'], ['arivenchy', 'killinit'], ['PlayWithYourFears'], [], [], [], ['Ps8'], [], ['aladdin'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['elwariato', 'fitlovers'], [], [], ['friday', 'idontcare'], [], [], [], [], [], [], [], [], [], [], [], ['kuwtk'], ['happykids'], [], [], ['nowplaying'], [], ['VeganFashion'], ['FENTYBEAUTYxBOOTS'], ['FBSUMMERTAKEOVA'], ['damn'], ['amazing'], [], [], [], [], [], [], [], [], [], ['SpiderManFarFromHome'], ['TommyxZendaya', 'Flashbacks'], [], ['ariesbaby'], [], ['DontUseMeth'], ['RealisRare'], [], [], [], [], [], ['poosh'], [], [], ['NM5'], [], ['Caiah'], ['FendiPrintsOn'], ['Zurich'], [], [], ['MYTRUTH', 'mycalvins'], ['MYTRUTH'], [], [], ['IfICantHaveYou'], ['love'], [], ['metoo', 'cancer'], ['G7', 'metoo', 'rolemodel'], ['metoo'], [], ['BFIFlare', 'alphabet'], ['metoo'], ['internationalwomensday'], [], ['kaichengthom'], ['g7biarritz', 'typo'], ['animalshumping'], [], ['Bill'], [], [], [], [], [], [], [], [], ['Medicine'], [], [], ['PalmerayYo'], [], [], [], [], ['beautiful'], [], [], [], [], ['ZaynbyTheKooples'], [], [], [], ['valverdeout', 'ValverdeOut', 'valverdeout', 'valverdeout', 'valverdeout'], ['ValverdeOut', 'Valverdeout', 'valvardeOut', 'valverdeout'], ['valverdeout', 'valverdeout', 'valverdeout', 'valverdeout', 'valverdeout', 'valverdeout'], ['valverdeout', 'valvardeout', 'valverdeout', 'valverdeout', 'valverdeout', 'dembele'], ['valverdeout', 'ValverdeOut', 'valverdeout', 'valverdeout', 'valverdeout', 'valverdeout'], ['valverdeout', 'valverdeoutreble'], [], ['valverdeout', 'Valverde', 'ValverdeOut', 'valverdeout', 'bartomeuout', 'valverdeout', 'valverdeout'], ['UCL', 'valverdeOUT', 'dembele'], ['tbt', 'bts'], ['TeamDowney'], ['TeamStark'], ['tbt'], ['flashbackfriday'], ['tbt', 'bestactor', 'kindofmarvel'], ['VineyardVinesForTarget'], ['jasmine'], [], ['MothersDay'], [], ['beetlejuice'], ['MetGala2019'], ['MetGala2019'], ['MetGala2019'], ['stupid'], ['mustbeloveonthe'], ['metgala2019'], [], [], [], [], [], [], [], [], [], [], [], ['nohomo'], [], ['spidermanfarfromhome'], ['spidermanfarfromhome', 'Crush'], ['chaoswalking', 'Crush'], ['2', '2001', 'heartpalpitations', 'sadphillyboy'], ['RepresentationMatters'], [], ['GOAT'], [], ['TBT'], [], ['WEY'], ['wavey'], ['nopromises'], [], ['happymothersday'], ['GotInked', 'votekar'], [], [], ['one8'], ['RCB'], [], ['playbold', 'followme', 'as'], ['jay_hind'], [], [], [], [], [], [], [], [], [], [], [], [], ['1YearOfRaazi'], [], [], [], ['HookUpSong'], ['HookUpSong'], ['Brahmastra'], ['hookupsong'], [], [], ['OurOtherClub'], [], [], [], [], ['MiaSanMia'], [], [], [], [], ['hausofgaga'], ['help'], ['metgala'], [], ['METGALA', 'love'], ['METGALA', '2'], ['METGALA', 'metgaga', 'metgala2019'], ['METGALA', 'METGALA'], [], ['MetGala'], ['MetGala', 'naturalbeautyqueen'], [], ['soshockingitblewmywigoff'], ['drogonyouhavemyheart4lyfe'], ['onlyatomaze'], ['serjorahforlyfe'], ['foxyroxy', 'barkhappy'], [], ['kitharrington'], ['ifonlyiwokeuplikethat'], ['artlivesandbreathes', 'hero'], [], [], ['2019'], [], [], ['gossipgirl'], [], ['justvoted'], ['Pusegav'], [], [], [], [], [], ['itonlyhappensatsunglasshut', 'beauty'], ['vitas'], ['PradaSS19'], [], [], [], ['olivierrizzo'], [], [], [], [], ['riverdale'], [], [], [], ['fivefeetapart'], ['favouritecouple'], ['riverdale'], [], [], ['redbullcapefear'], ['mum'], ['chrisevans'], ['scarlettjohansson'], ['avengersendgame'], [], [], [], [], ['Kimmel'], ['extremelywicked'], ['londontown', 'soyjovenfuerte'], ['extremelywicked', 'extremelywicked'], [], [], [], [], ['Authentic'], ['familygoals', 'freequotes', 'striveforgreatness'], ['DONCHEADLE', 'Elevate'], [], ['BuyBackToYouOniTunes'], ['Vanatta'], [], [], [], [], [], [], [], ['SilverFox'], ['Repost'], [], [], [], ['SHARE'], [], [], ['time100'], [], ['warstdunichtManCityFan'], [], ['ad'], ['ninicam'], [], [], [], [], [], [], [], [], ['RMLiga', 'we', 'Hala_madrid'], ['RMLiga', 'HalaMadrid', 'HalaMadrid', 'modric', 'navasquedate'], ['HalaMadrid'], ['RMCity'], ['RMLiga', 'agsu'], ['Emirates'], ['FuerzaIker'], ['XMenDay', '2', 'DeadPool3', 'familyisnotafword'], ['arbaeenwalk'], ['DetectivePikachu', 'supportluke', 'DetectivePikachu'], ['DetectivePikachu'], ['detectivepikachu', 'detectivepikachumovie'], ['HitmansBodyguard2'], ['MaximumEffort'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['transmenarerealmen'], [], ['youtube']]\n"
     ]
    }
   ],
   "source": [
    "print(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n",
      "425\n"
     ]
    }
   ],
   "source": [
    "print(len(INDIVIDUAL_POST_URLS))\n",
    "print(len(COMMENTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['28.9k', '31k', '42.3k', '28.1k', '29.7k', '18.4k', '46.9k', '13.1k', '55.2k', '26.7k', '58.8k', '152.1k', '22.5k', '25.1k', '69.1k', '183.4k', '44.6k', '73.2k', '10k', '75.5k', '539', '898', '19.2k', '33.2k', '72.2k', '97.3k', '55.9k', '53.2k', '60.6k', '18k', '55k', '15.7k', '153.8k', '95k', '15.2k', '28.5k', '23.9k', '11.7k', '31.9k', '22.3k', '15.1k', '35.9k', '80.5k', '88.7k', '50.3k', '19.5k', '23.7k', '30.5k', '948', '22.3k', '969', '524', '17.1k', '122.2k', '22.3k', '20.8k', '21.7k', '414', '196', '656', '350', '388', '957', '850', '607', '351', '12.3k', '21.2k', '458', '435', '788', '10.4k', '14.6k', '439', '594', '324', '637', '16.9k', '28.9k', '63.9k', '463', '11.1k', '842', '196', '149', '15.6k', '13.7k', '11.2k', '395', '17.2k', '991', '18.1k', '277', '044', '444', '10.5k', '329', '5', '7', '12', '25', '66', '11', '169', '32', '21', '32.3k', '719', '38.6k', '61.5k', '51.4k', '986', '31.4k', '33.4k', '65.9k', '83.2k', '0', '0', '0', '0', '0', '0', '0', '0', '13.5k', '17.1k', '21.4k', '21.4k', '015', '423', '091', '483', '209', '17.7k', '549', '858', '942', '13.2k', '614', '924', '017', '005', '067', '10.1k', '39.7k', '15.1k', '33k', '12.9k', '41.5k', '18.3k', '21.1k', '18.2k', '839', '419', '631', '440', '933', '44.1k', '19.4k', '23.2k', '11.9k', '53.3k', '329', '957', '363', '973', '895', '12.5k', '304', '11.7k', '741', '444', '23.6k', '522', '32.6k', '53.8k', '233k', '27k', '32.3k', '10.5k', '645', '542', '524', '460', '910', '47.8k', '374', '13.5k', '936', '430', '979', '494', '27.8k', '30.1k', '40.5k', '63.3k', '24.9k', '42.3k', '36.2k', '34.4k', '32.9k', '840', '19.2k', '661', '277', '400', '11.5k', '41.4k', '12.4k', '10.9k', '22k', '11.4k', '48.8k', '10.5k', '46.9k', '46.6k', '27.6k', '84.3k', '41.7k', '31.5k', '21.1k', '563', '248', '249', '826', '16.5k', '22k', '34.9k', '168.5k', '101.7k', '839', '47.4k', '87.2k', '120.9k', '128.6k', '944', '821', '129', '089', '093', '137', '24.4k', '970', '12.7k', '418', '334', '039', '36.2k', '27.2k', '39.1k', '63.4k', '16.3k', '19.1k', '18k', '12.9k', '104', '59', '40', '266', '79', '71', '44', '92', '41', '35', '43', '16.2k', '21.2k', '14.7k', '15.6k', '20.6k', '23.4k', '16.7k', '36.3k', '25k', '12.4k', '15k', '424', '686', '383', '13.7k', '10.4k', '790', '429', '413', '567', '548', '856', '971', '762', '625', '575', '11.1k', '14.3k', '901', '10.1k', '352', '606', '093', '190', '723', '429', '20.1k', '006', '032', '018', '18.6k', '34.5k', '25k', '50k', '16.7k', '133', '77.4k', '262', '11.2k', '12.4k', '496', '354', '944', '592', '481', '238', '692', '763', '023', '148', '499', '089', '587', '12.7k', '12.1k', '600', '15.9k', '515', '33.7k', '22k', '26.6k', '10.8k', '41.2k', '610', '761', '079', '15k', '20.4k', '23k', '588', '074', '12.1k', '691', '169', '596', '429', '155', '815', '076', '196', '275', '696', '356', '231', '10.8k', '14.7k', '15.1k', '021', '682', '670', '920', '20.5k', '784', '20.8k', '19.1k', '321', '10.2k', '30.6k', '847', '44.4k', '14.8k', '17.2k', '15.5k', '23.6k', '818', '428', '25.4k', '769', '18.5k', '10.3k', '11.3k', '17.1k', '21.2k', '12.6k', '28.8k', '22.4k', '832', '10.9k', '911', '429', '104', '189', '337', '079', '699', '416', '246', '355', '747', '949', '539', '178', '425', '709', '578', '623', '933', '634', '229.4k', '18.4k', '17.2k', '20.7k', '17.7k', '22.9k', '13.3k', '30.5k', '327', '51.5k', '22.3k']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(COMMENTS)):\n",
    "    try:\n",
    "        index = str.find(\"k\", COMMENTS[i])\n",
    "        COMMENTS[i]= (COMMENTS[i])[0:index-8]\n",
    "    except:\n",
    "        COMMENTS[i] = int(COMMENTS[i])\n",
    "print(COMMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28900, 31000, 42300, 28100, 29700, 18400, 46900, 13100, 55200, 26700, 58800, 152100, 22500, 25100, 69100, 183400, 44600, 73200, 10000, 75500, 539, 898, 19200, 33200, 72200, 97300, 55900, 53200, 60600, 18000, 55000, 15700, 153800, 95000, 15200, 28500, 23900, 11700, 31900, 22300, 15100, 35900, 80500, 88700, 50300, 19500, 23700, 30500, 948, 22300, 969, 524, 17100, 122200, 22300, 20800, 21700, 414, 196, 656, 350, 388, 957, 850, 607, 351, 12300, 21200, 458, 435, 788, 10400, 14600, 439, 594, 324, 637, 16900, 28900, 63900, 463, 11100, 842, 196, 149, 15600, 13700, 11200, 395, 17200, 991, 18100, 277, 44, 444, 10500, 329, 5, 7, 12, 25, 66, 11, 169, 32, 21, 32300, 719, 38600, 61500, 51400, 986, 31400, 33400, 65900, 83200, 0, 0, 0, 0, 0, 0, 0, 0, 13500, 17100, 21400, 21400, 15, 423, 91, 483, 209, 17700, 549, 858, 942, 13200, 614, 924, 17, 5, 67, 10100, 39700, 15100, 33000, 12900, 41500, 18300, 21100, 18200, 839, 419, 631, 440, 933, 44100, 19400, 23200, 11900, 53300, 329, 957, 363, 973, 895, 12500, 304, 11700, 741, 444, 23600, 522, 32600, 53800, 233000, 27000, 32300, 10500, 645, 542, 524, 460, 910, 47800, 374, 13500, 936, 430, 979, 494, 27800, 30100, 40500, 63300, 24900, 42300, 36200, 34400, 32900, 840, 19200, 661, 277, 400, 11500, 41400, 12400, 10900, 22000, 11400, 48800, 10500, 46900, 46600, 27600, 84300, 41700, 31500, 21100, 563, 248, 249, 826, 16500, 22000, 34900, 168500, 101700, 839, 47400, 87200, 120900, 128600, 944, 821, 129, 89, 93, 137, 24400, 970, 12700, 418, 334, 39, 36200, 27200, 39100, 63400, 16300, 19100, 18000, 12900, 104, 59, 40, 266, 79, 71, 44, 92, 41, 35, 43, 16200, 21200, 14700, 15600, 20600, 23400, 16700, 36300, 25000, 12400, 15000, 424, 686, 383, 13700, 10400, 790, 429, 413, 567, 548, 856, 971, 762, 625, 575, 11100, 14300, 901, 10100, 352, 606, 93, 190, 723, 429, 20100, 6, 32, 18, 18600, 34500, 25000, 50000, 16700, 133, 77400, 262, 11200, 12400, 496, 354, 944, 592, 481, 238, 692, 763, 23, 148, 499, 89, 587, 12700, 12100, 600, 15900, 515, 33700, 22000, 26600, 10800, 41200, 610, 761, 79, 15000, 20400, 23000, 588, 74, 12100, 691, 169, 596, 429, 155, 815, 76, 196, 275, 696, 356, 231, 10800, 14700, 15100, 21, 682, 670, 920, 20500, 784, 20800, 19100, 321, 10200, 30600, 847, 44400, 14800, 17200, 15500, 23600, 818, 428, 25400, 769, 18500, 10300, 11300, 17100, 21200, 12600, 28800, 22400, 832, 10900, 911, 429, 104, 189, 337, 79, 699, 416, 246, 355, 747, 949, 539, 178, 425, 709, 578, 623, 933, 634, 229400, 18400, 17200, 20700, 17700, 22900, 13300, 30500, 327, 51500, 22300]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(COMMENTS)):    ## get rid of the '.'\n",
    "    COMMENTS[i] = str(COMMENTS[i])\n",
    "    if not COMMENTS[i] == 0:\n",
    "        if '.' in COMMENTS[i]:\n",
    "            COMMENTS[i] = re.sub('\\.', '', COMMENTS[i])\n",
    "            if COMMENTS[i][-1] == 'k':\n",
    "                temp = COMMENTS[i]\n",
    "                thousands = temp[:len(temp)-1] + '00'\n",
    "                COMMENTS[i] = thousands\n",
    "            if COMMENTS[i][-1] == 'm':\n",
    "                temp = COMMENTS[i]\n",
    "                thousands = temp[:len(temp)-1] + '00000'\n",
    "                COMMENTS[i] = thousands\n",
    "        COMMENTS[i] = re.sub(',', '', COMMENTS[i])\n",
    "        if COMMENTS[i][-1] == 'k':\n",
    "            temp = COMMENTS[i]\n",
    "            thousands = temp[:len(temp)-1] + '000'\n",
    "            COMMENTS[i] = int(thousands)\n",
    "        elif COMMENTS[i][-1] == 'm':\n",
    "            temp = COMMENTS[i]\n",
    "            thousands = temp[:len(temp)-1] + '000000'\n",
    "            COMMENTS[i] = int(thousands)\n",
    "        else:\n",
    "            COMMENTS[i] = int(str(COMMENTS[i]))    \n",
    "print(COMMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n",
      "425\n",
      "18052\n",
      "461\n",
      "451\n"
     ]
    }
   ],
   "source": [
    "####  TEMPORARY FIX #### TODO: COME BACK AND FIX THIS!!!\n",
    "print(len(INDIVIDUAL_POST_URLS))\n",
    "print(len(COMMENTS))\n",
    "\n",
    "temp = []\n",
    "avg_comments = int(numpy.mean(COMMENTS))\n",
    "print(avg_comments)\n",
    "for i in range(447-421):\n",
    "    temp.append(avg_comments)\n",
    "for x in temp:\n",
    "    COMMENTS.append(x)\n",
    "print(len(INDIVIDUAL_POST_URLS))\n",
    "print(len(COMMENTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n",
      "[['finoallafine'], [], ['pestanacr7'], ['finoallafine'], [], ['TopTraining'], [], [], [], [], ['followme'], [], [], ['90svintage'], [], [], ['CoachNY'], ['Haverdade'], [], [], ['COMINGSOON'], [], ['HappyMothersDay'], ['KYLIESKIN'], ['KylieSkin', 'healthylifestyle'], [], [], ['healthylifestyle'], [], [], [], [], [], [], [], [], [], ['OurOtherClub'], ['ultraboost'], ['sailormoon', 'sailormoon', 'NaarNewYork'], ['DADABHIGHENDAPPAREL'], [], [], [], ['freebritney', 'beastmode'], ['RIP'], ['STAY_STRONG'], ['blacklove'], [], ['crueltynotfashion'], [], [], ['TiffanyBlueBook'], [], ['MOONbyKendall'], ['moon_partner'], [], [], ['MYCALVINS'], ['JUMANJI', '_classic_mode99', 'followme'], [], [], ['JUMANJI'], ['JUMANJI'], ['JUMANJI', 'goodpeople'], ['JUMANJI'], ['JUMANJI'], ['gratefulSOB'], ['KKWBEAUTY', 'dreamsdocometrue'], ['BestFriendsAss'], [], [], [], [], ['KKWBEAUTY', 'kkwbeauty', 'kkwbeauty'], ['KKWBEAUTY', 'kkwbeauty'], ['KKWBEAUTY'], [], [], [], ['MothersDay'], [], ['WeeklyFluff'], ['Ramadan', '_classic_mode99'], ['APAheritagemonth'], [], ['WHPgoingplaces'], ['WeeklyFluff'], [], [], [], [], ['topsinger'], ['arivenchy'], [], ['arivenchy', 'longhair'], ['arivenchy', 'killinit'], ['PlayWithYourFears'], [], [], [], ['Ps8'], [], ['aladdin'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['elwariato', 'fitlovers'], [], [], ['friday', 'idontcare'], [], [], [], [], [], [], [], [], [], [], [], ['kuwtk'], ['happykids'], [], [], ['nowplaying'], [], ['VeganFashion'], ['FENTYBEAUTYxBOOTS'], ['FBSUMMERTAKEOVA'], ['damn'], ['amazing'], [], [], [], [], [], [], [], [], [], ['SpiderManFarFromHome'], ['TommyxZendaya', 'Flashbacks'], [], ['ariesbaby'], [], ['DontUseMeth'], ['RealisRare'], [], [], [], [], [], ['poosh'], [], [], ['NM5'], [], ['Caiah'], ['FendiPrintsOn'], ['Zurich'], [], [], ['MYTRUTH', 'mycalvins'], ['MYTRUTH'], [], [], ['IfICantHaveYou'], ['love'], [], ['metoo', 'cancer'], ['G7', 'metoo', 'rolemodel'], ['metoo'], [], ['BFIFlare', 'alphabet'], ['metoo'], ['internationalwomensday'], [], ['kaichengthom'], ['g7biarritz', 'typo'], ['animalshumping'], [], ['Bill'], [], [], [], [], [], [], [], [], ['Medicine'], [], [], ['PalmerayYo'], [], [], [], [], ['beautiful'], [], [], [], [], ['ZaynbyTheKooples'], [], [], [], ['valverdeout', 'ValverdeOut', 'valverdeout', 'valverdeout', 'valverdeout'], ['ValverdeOut', 'Valverdeout', 'valvardeOut', 'valverdeout'], ['valverdeout', 'valverdeout', 'valverdeout', 'valverdeout', 'valverdeout', 'valverdeout'], ['valverdeout', 'valvardeout', 'valverdeout', 'valverdeout', 'valverdeout', 'dembele'], ['valverdeout', 'ValverdeOut', 'valverdeout', 'valverdeout', 'valverdeout', 'valverdeout'], ['valverdeout', 'valverdeoutreble'], [], ['valverdeout', 'Valverde', 'ValverdeOut', 'valverdeout', 'bartomeuout', 'valverdeout', 'valverdeout'], ['UCL', 'valverdeOUT', 'dembele'], ['tbt', 'bts'], ['TeamDowney'], ['TeamStark'], ['tbt'], ['flashbackfriday'], ['tbt', 'bestactor', 'kindofmarvel'], ['VineyardVinesForTarget'], ['jasmine'], [], ['MothersDay'], [], ['beetlejuice'], ['MetGala2019'], ['MetGala2019'], ['MetGala2019'], ['stupid'], ['mustbeloveonthe'], ['metgala2019'], [], [], [], [], [], [], [], [], [], [], [], ['nohomo'], [], ['spidermanfarfromhome'], ['spidermanfarfromhome', 'Crush'], ['chaoswalking', 'Crush'], ['2', '2001', 'heartpalpitations', 'sadphillyboy'], ['RepresentationMatters'], [], ['GOAT'], [], ['TBT'], [], ['WEY'], ['wavey'], ['nopromises'], [], ['happymothersday'], ['GotInked', 'votekar'], [], [], ['one8'], ['RCB'], [], ['playbold', 'followme', 'as'], ['jay_hind'], [], [], [], [], [], [], [], [], [], [], [], [], ['1YearOfRaazi'], [], [], [], ['HookUpSong'], ['HookUpSong'], ['Brahmastra'], ['hookupsong'], [], [], ['OurOtherClub'], [], [], [], [], ['MiaSanMia'], [], [], [], [], ['hausofgaga'], ['help'], ['metgala'], [], ['METGALA', 'love'], ['METGALA', '2'], ['METGALA', 'metgaga', 'metgala2019'], ['METGALA', 'METGALA'], [], ['MetGala'], ['MetGala', 'naturalbeautyqueen'], [], ['soshockingitblewmywigoff'], ['drogonyouhavemyheart4lyfe'], ['onlyatomaze'], ['serjorahforlyfe'], ['foxyroxy', 'barkhappy'], [], ['kitharrington'], ['ifonlyiwokeuplikethat'], ['artlivesandbreathes', 'hero'], [], [], ['2019'], [], [], ['gossipgirl'], [], ['justvoted'], ['Pusegav'], [], [], [], [], [], ['itonlyhappensatsunglasshut', 'beauty'], ['vitas'], ['PradaSS19'], [], [], [], ['olivierrizzo'], [], [], [], [], ['riverdale'], [], [], [], ['fivefeetapart'], ['favouritecouple'], ['riverdale'], [], [], ['redbullcapefear'], ['mum'], ['chrisevans'], ['scarlettjohansson'], ['avengersendgame'], [], [], [], [], ['Kimmel'], ['extremelywicked'], ['londontown', 'soyjovenfuerte'], ['extremelywicked', 'extremelywicked'], [], [], [], [], ['Authentic'], ['familygoals', 'freequotes', 'striveforgreatness'], ['DONCHEADLE', 'Elevate'], [], ['BuyBackToYouOniTunes'], ['Vanatta'], [], [], [], [], [], [], [], ['SilverFox'], ['Repost'], [], [], [], ['SHARE'], [], [], ['time100'], [], ['warstdunichtManCityFan'], [], ['ad'], ['ninicam'], [], [], [], [], [], [], [], [], ['RMLiga', 'we', 'Hala_madrid'], ['RMLiga', 'HalaMadrid', 'HalaMadrid', 'modric', 'navasquedate'], ['HalaMadrid'], ['RMCity'], ['RMLiga', 'agsu'], ['Emirates'], ['FuerzaIker'], ['XMenDay', '2', 'DeadPool3', 'familyisnotafword'], ['arbaeenwalk'], ['DetectivePikachu', 'supportluke', 'DetectivePikachu'], ['DetectivePikachu'], ['detectivepikachu', 'detectivepikachumovie'], ['HitmansBodyguard2'], ['MaximumEffort'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['transmenarerealmen'], [], ['youtube']]\n"
     ]
    }
   ],
   "source": [
    "print(len(hashtags))\n",
    "print(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2034640], [0], [12436], [2034640], [0], [20101], [0], [0], [0], [0], [481056176], [0], [0], [364957], [0], [0], [74344], [14], [0], [0], [15354283], [0], [9716748], [2537], [2537, 47311156], [0], [0], [47311157], [0], [0], [0], [0], [0], [0], [0], [0], [0], [3657], [2494183], [3783165, 3783165, 9], [269], [0], [0], [0], [19549, 24321207], [24203590], [43455], [4843271], [0], [1], [0], [0], [10797], [0], [58], [197], [0], [0], [701377], [373086, 17, 481056193], [0], [0], [373086], [373086], [373086, 2772675], [373086], [373086], [127], [[0], [0]], [[0]], [0], [0], [0], [0], [[0], [0], [0]], [[0], [0]], [[0]], [0], [0], [0], [[0]], [0], [[0]], [[0], [0]], [[0]], [0], [[0]], [[0]], [0], [0], [0], [0], [[0]], [[0]], [0], [[0], [0]], [[0], [0]], [[0]], [0], [0], [0], [[0]], [0], [[0]], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [[0], [0]], [0], [0], [[0], [0]], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [[0]], [[0]], [0], [0], [[0]], [0], [[0]], [[0]], [[0]], [[0]], [[0]], [0], [0], [0], [0], [0], [0], [0], [0], [0], [[0]], [[0], [0]], [0], [[0]], [0], [[0]], [[0]], [0], [0], [0], [0], [0], [[0]], [0], [0], [[0]], [0], [[0]], [[0]], [[0]], [0], [0], [[0], [0]], [[0]], [0], [0], [[0]], [[0]], [0], [[0], [0]], [[0], [0], [0]], [[0]], [0], [[0], [0]], [[0]], [[0]], [0], [[0]], [[0], [0]], [[0]], [0], [[0]], [0], [0], [0], [0], [0], [0], [0], [0], [[0]], [0], [0], [[0]], [0], [0], [0], [0], [[0]], [0], [0], [0], [0], [[0]], [0], [0], [0], [[0], [0], [0], [0], [0]], [[0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0]], [[0], [0], [0], 3902, 3902, 476148], [3902, 3902, 3902, 3902, 3902, 3902], [3902, 4], [0], [3902, 128461, 3902, 3902, [0], [0], [0]], [[0], [0], [0]], [[0], [0]], [[0]], [[0]], [[0]], [[0]], [[0], [0], [0]], [[0]], [[0]], [0], [[0]], [0], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [[0]], [0], [[0]], [[0], [0]], [[0], [0]], [[0], [0], [0], [0]], [[0]], [0], [[0]], [0], [[0]], [0], [[0]], [[0]], [[0]], [0], [[0]], [[0], [0]], [0], [0], [[0]], [[0]], [0], [[0], [0], [0]], [[0]], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [[0]], [0], [0], [0], [[0]], [[0]], [[0]], [[0]], [0], [0], [[0]], [0], [0], [0], [0], [[0]], [0], [0], [0], [0], [[0]], [[0]], [[0]], [0], [[0], [0]], [[0], [0]], [[0], [0], [0]], [[0], [0]], [0], [[0]], [[0], [0]], [0], [[0]], [[0]], [[0]], [[0]], [[0], [0]], [0], [[0]], [[0]], [[0], [0]], [0], [0], [[0]], [0], [0], [[0]], [0], [[0]], [[0]], [0], [0], [0], [0], [0], [[0], [0]], [[0]], [12318], [0], [0], [0], [12222], [0], [0], [0], [0], [5614708], [0], [0], [0], [64586], [21070], [5614708], [0], [0], [2212], [11604039], [1971551], [1182475], [2565332], [0], [0], [0], [0], [34327], [2573], [1325039, 474], [2573, 2573], [0], [0], [0], [0], [10165986], [6340233, 60355, 2253253], [52082, 993833], [0], [142], [56], [0], [0], [0], [0], [0], [0], [0], [447645], [402871758], [0], [0], [0], [19331437], [0], [0], [63800], [0], [[0]], [0], [8857307], [29773], [0], [0], [0], [0], [0], [0], [0], [0], [225021, 11544491, 518060], [225021, 8574696, 8574696, 871516, 1], [8574696], [[0]], [[0], [0]], [[0]], [[0]], [[0], [0], [0], [0]], [[0]], [[0], [0], [0]], [[0]], [[0], [0]], [[0]], [[0]], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [[0]], [0], [[0]]]\n"
     ]
    }
   ],
   "source": [
    "all_hashtags = []\n",
    "    \n",
    "for i in range(len(hashtags)):\n",
    "    arr = []\n",
    "    for x in range(len(hashtags[i])):\n",
    "        arr.append(\"https://www.instagram.com/explore/tags/\" + (hashtags[i])[x] + \"/\")\n",
    "    all_hashtags.append(arr) \n",
    "\n",
    "tag_total_counts = []\n",
    "for tag_url in all_hashtags:\n",
    "    post_f_count = []\n",
    "    if not len(tag_url) == 0:\n",
    "        for each in tag_url:\n",
    "            if not len(each) == 0:    # why tho\n",
    "                try:\n",
    "                    driver.get(str(each))\n",
    "                    site_source = driver.page_source    # html source code\n",
    "                    soup = BeautifulSoup(site_source, 'html.parser')\n",
    "                    soup.prettify()\n",
    "\n",
    "                    num_loc = soup.find_all('script',{'type': 'text/javascript'})\n",
    "                    count = re.findall('\"count\":([0-9]+),\"page_info\"', str(num_loc))\n",
    "                    count = str(count)     # format: \"['13941']\"\n",
    "                    count = count[2:len(count)-2]\n",
    "                    if \",\" in count:\n",
    "                        index = str.find(\",\", count)\n",
    "                        count = count[0:index] + count[index+1:]    # format: \"['13941']\"\n",
    "                        count = count[2:len(count)-2]\n",
    "                    post_f_count.append(int(count))\n",
    "                except:\n",
    "                    post_f_count.append([0])\n",
    "            else:\n",
    "                post_f_count.append([0])\n",
    "        tag_total_counts.append(post_f_count)\n",
    "    else:\n",
    "        tag_total_counts.append([0])\n",
    "print(tag_total_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n",
      "461\n",
      "461\n"
     ]
    }
   ],
   "source": [
    "print(len(tag_total_counts))\n",
    "print(len(all_hashtags))\n",
    "print(len(INDIVIDUAL_POST_URLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = zip(FINAL_POSTED_BY, INDIVIDUAL_POST_URLS, tagged_users_array, tagged_user_followers, hashtags, tag_total_counts, COMMENTS, LIKES_ARRAY)\n",
    "\n",
    "with open('data_2.csv', \"w\") as f:    # w = writable\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"posted by\", \"post url\", \"tagged users\", \"tagged users followers\", \"tags\", \"tag post totals\", \"comments\", \"likes\"])\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = zip(usernames, FOLLOWERS)\n",
    "    \n",
    "with open('user_data.csv', \"w\") as f:    # w = writable\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"username\", \"followers\"])\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
